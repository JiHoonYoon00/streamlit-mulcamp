{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89043bc8-77b6-435d-9e03-3fb061276465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.31.0\n",
      "4.12.3\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import bs4\n",
    "\n",
    "print(requests.__version__)\n",
    "print(bs4.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fafffd-838d-4329-9859-215a85c6a83f",
   "metadata": {},
   "source": [
    "## 네이버 상태 코드\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "547116dd-9939-47af-ad73-b6881eae1ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "URL = 'https://www.naver.com/'\n",
    "\n",
    "req = requests.get(URL)\n",
    "print(req.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fe5a8d7-3289-4466-8120-397415773a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#req.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4058120e-d415-495b-8ca1-8f1904a153ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<li>애플</li>, <li>삼성</li>, <li>노키아</li>, <li>LG</li>]\n",
      "['애플', '삼성', '노키아', 'LG']\n",
      "   회사명\n",
      "0   애플\n",
      "1   삼성\n",
      "2  노키아\n",
      "3   LG\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "import pandas as pd \n",
    "\n",
    "with open('index.html', 'r', encoding='UTF8') as f:\n",
    "\n",
    "    # step 01 : 데이터 수집\n",
    "    contents = f.read()\n",
    "\n",
    "    # step 02 : 데이터 파싱 (순수한 HTML 파일을 BeautifulSoup 객체로 변환)\n",
    "    # 농구공(=HTML, 문자열) ===> 규칙 (농구장)\n",
    "    # 농구공 ===> 축구장(크롤링)으로 던짐 (농구공이 축구공으로 변하는 매직) BeautifulSoup() 클래스를 통해서 축구공으로 변함\n",
    "    # 축구(=BeautifulSoup 클래스 문법)규칙 을 따르면 됨\n",
    "    \n",
    "    soup = BeautifulSoup(contents, 'lxml')\n",
    "    # print(soup)\n",
    "    \n",
    "#     print(soup.h2)\n",
    "#     print(soup.ul)\n",
    "#     print(\"-----\")\n",
    "#    print(soup.ul.li)\n",
    "    # 4개의 li 태그에 있는 회사명을 모두 가져오는 것이 목적\n",
    "\n",
    "    # step 03 : 데이터 수집 위한 특정 태그 찾기\n",
    "    companies = []\n",
    "    print(soup.find_all('li'))\n",
    "\n",
    "    # step 04 : 데이터 가공\n",
    "    for tag in soup.find_all('li'):\n",
    "        companies.append(tag.text)\n",
    "    print(companies)\n",
    "\n",
    "    # step 05 : 처리된 데이터 저장 pandas 데이터프레임\n",
    "    crawling_dict = {'회사명': companies}\n",
    "    result = pd.DataFrame(crawling_dict)\n",
    "    print(result)\n",
    "\n",
    "    # step 06 : csv 파일로 내보내기 or DB로 내보내기\n",
    "    result.to_csv(\"result.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5521176-cc8b-49e0-9019-73af920ac2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  곡\n",
      "0                 \\nLove wins all\\n\n",
      "1                          \\nWife\\n\n",
      "2                         \\nTo. X\\n\n",
      "3                      \\nLove 119\\n\n",
      "4                          \\n에피소드\\n\n",
      "..                              ...\n",
      "95  \\n머물러주오 (Prod. 안신애 & Philtre)\\n\n",
      "96                       \\n운이 좋았지\\n\n",
      "97                      \\nSnowman\\n\n",
      "98                \\nCool With You\\n\n",
      "99         \\n사랑은 먼 길을 돌아온 메아리 같아서\\n\n",
      "\n",
      "[100 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd  \n",
    "\n",
    "custom_header = {\n",
    "\t'referer' : 'https://music.bugs.co.kr/',\n",
    "\t'user-agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'\n",
    "}\n",
    "\n",
    "\n",
    "url = \"https://music.bugs.co.kr/chart\" # 크롤링 하려는 웹사이트\n",
    "req = requests.get(url, headers = custom_header)\n",
    "\n",
    "# 페이지의 HTML을 BeautifulSoup 객체로 변환\n",
    "soup = BeautifulSoup(req.content, 'html.parser') #text, tbody\n",
    "\n",
    "# 노래 제목 추출\n",
    "\n",
    "song = []\n",
    "for title in soup.find_all('p',class_ ='title'):\n",
    "    song.append(title.text)\n",
    "#print(song)\n",
    "\n",
    "# 데이터프레임 생성\n",
    "df = pd.DataFrame({'곡': song})\n",
    "\n",
    "# 결과 출력\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb7d2cd8-7483-4905-ae4e-fc5f1eda403a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              노래제목\n",
      "0                    Love wins all\n",
      "1                             Wife\n",
      "2                         Love 119\n",
      "3                            To. X\n",
      "4                             에피소드\n",
      "..                             ...\n",
      "95                         사랑을 하다가\n",
      "96  Smoke (Prod. Dynamicduo, Padi)\n",
      "97                        미워 (Ego)\n",
      "98                           밤, 바다\n",
      "99            사랑은 먼 길을 돌아온 메아리 같아서\n",
      "\n",
      "[100 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#강사님 코드\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd \n",
    "\n",
    "def crawling(soup) :\n",
    "    # print(soup)\n",
    "    tbody = soup.find(\"tbody\")  #이부분 다시공부\n",
    "    result = []\n",
    "    for p in tbody.find_all('p', class_ = 'title'):\n",
    "        result.append(p.get_text().strip())\n",
    "    return result\n",
    "\n",
    "def main() :\n",
    "    custom_header = {\n",
    "        'referer' : 'https://music.bugs.co.kr/',\n",
    "        'user-agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'\n",
    "    }\n",
    "    url = \"https://music.bugs.co.kr/chart\" # 크롤링 하려는 웹사이트\n",
    "    req = requests.get(url, headers = custom_header)\n",
    "    \n",
    "    soup = BeautifulSoup(req.text, \"html.parser\")\n",
    "    crawling(soup)\n",
    "\n",
    "    titles = crawling(soup)\n",
    "    print(pd.DataFrame({\"노래제목\" : titles}))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\" :\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "330d6ac2-f7ed-4819-b12a-416599b442e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>날짜</th>\n",
       "      <th>종가</th>\n",
       "      <th>전일비</th>\n",
       "      <th>시가</th>\n",
       "      <th>고가</th>\n",
       "      <th>저가</th>\n",
       "      <th>거래량</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024.01.31</td>\n",
       "      <td>72700.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>73400.0</td>\n",
       "      <td>74000.0</td>\n",
       "      <td>72500.0</td>\n",
       "      <td>14874547.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024.01.30</td>\n",
       "      <td>74300.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>75300.0</td>\n",
       "      <td>73700.0</td>\n",
       "      <td>12244418.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024.01.29</td>\n",
       "      <td>74400.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>73800.0</td>\n",
       "      <td>75200.0</td>\n",
       "      <td>73500.0</td>\n",
       "      <td>13976521.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024.01.26</td>\n",
       "      <td>73400.0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>73700.0</td>\n",
       "      <td>74500.0</td>\n",
       "      <td>73300.0</td>\n",
       "      <td>11160062.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>2023.08.09</td>\n",
       "      <td>68900.0</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>68000.0</td>\n",
       "      <td>69600.0</td>\n",
       "      <td>67900.0</td>\n",
       "      <td>17259673.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>2023.08.08</td>\n",
       "      <td>67600.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>69000.0</td>\n",
       "      <td>69100.0</td>\n",
       "      <td>67400.0</td>\n",
       "      <td>14664709.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>2023.08.07</td>\n",
       "      <td>68500.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>67700.0</td>\n",
       "      <td>69200.0</td>\n",
       "      <td>67600.0</td>\n",
       "      <td>10968505.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>2023.08.04</td>\n",
       "      <td>68300.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>68800.0</td>\n",
       "      <td>69100.0</td>\n",
       "      <td>68200.0</td>\n",
       "      <td>12360193.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             날짜       종가     전일비       시가       고가       저가         거래량\n",
       "0           NaN      NaN     NaN      NaN      NaN      NaN         NaN\n",
       "1    2024.01.31  72700.0  1600.0  73400.0  74000.0  72500.0  14874547.0\n",
       "2    2024.01.30  74300.0   100.0  75000.0  75300.0  73700.0  12244418.0\n",
       "3    2024.01.29  74400.0  1000.0  73800.0  75200.0  73500.0  13976521.0\n",
       "4    2024.01.26  73400.0   700.0  73700.0  74500.0  73300.0  11160062.0\n",
       "..          ...      ...     ...      ...      ...      ...         ...\n",
       "175  2023.08.09  68900.0  1300.0  68000.0  69600.0  67900.0  17259673.0\n",
       "176  2023.08.08  67600.0   900.0  69000.0  69100.0  67400.0  14664709.0\n",
       "177  2023.08.07  68500.0   200.0  67700.0  69200.0  67600.0  10968505.0\n",
       "178  2023.08.04  68300.0   500.0  68800.0  69100.0  68200.0  12360193.0\n",
       "179         NaN      NaN     NaN      NaN      NaN      NaN         NaN\n",
       "\n",
       "[180 rows x 7 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import warnings\n",
    "import time\n",
    "import random\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "company_code = '005930' # 삼성전자\n",
    "url =\"https://finance.naver.com/item/sise_day.nhn?code=\" + company_code\n",
    "    \n",
    "headers = { \n",
    "             'referer' : 'https://finance.naver.com/item/sise.naver?code=005930',\n",
    "             'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'\n",
    "            }\n",
    "\n",
    "N = 12\n",
    "df =None\n",
    "\n",
    "for pageNum in range(1, N+1):\n",
    "    url=f'https://finance.naver.com/item/sise_day.naver?code=005930&page={pageNum}'\n",
    " \n",
    "    req = requests.get(url, headers=headers)\n",
    "    soup  = BeautifulSoup(req.content,\"html.parser\")\n",
    "    result = pd.read_html(req.text, encoding='euc-kr')[0] #리스트안에 판다스데이터프레임에 들어간 형태 type도 리스트로 나옴\n",
    "    #print(result)\n",
    "    df =pd.concat([df, result],ignore_index=True)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a7751384-a05f-40fe-bc7c-afada6cada09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "req = requests.get(url, headers=headers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "786ea695-2f87-4036-838a-a97f7dccfa3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dk/vy49vgx92_3d76t7s3b_x5c40000gn/T/ipykernel_97776/4192256325.py:1: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  pd.read_html(req.text, encoding='euc-kr')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[            날짜       종가     전일비       시가       고가       저가         거래량\n",
       " 0          NaN      NaN     NaN      NaN      NaN      NaN         NaN\n",
       " 1   2024.01.31  72700.0  1600.0  73400.0  74000.0  72600.0  12023736.0\n",
       " 2   2024.01.30  74300.0   100.0  75000.0  75300.0  73700.0  12244418.0\n",
       " 3   2024.01.29  74400.0  1000.0  73800.0  75200.0  73500.0  13976521.0\n",
       " 4   2024.01.26  73400.0   700.0  73700.0  74500.0  73300.0  11160062.0\n",
       " 5   2024.01.25  74100.0   100.0  74200.0  74800.0  73700.0  11737747.0\n",
       " 6          NaN      NaN     NaN      NaN      NaN      NaN         NaN\n",
       " 7          NaN      NaN     NaN      NaN      NaN      NaN         NaN\n",
       " 8          NaN      NaN     NaN      NaN      NaN      NaN         NaN\n",
       " 9   2024.01.24  74000.0  1200.0  75200.0  75200.0  73500.0  12860661.0\n",
       " 10  2024.01.23  75200.0   100.0  75700.0  75800.0  74300.0  14786224.0\n",
       " 11  2024.01.22  75100.0   400.0  75900.0  76000.0  75000.0  19673375.0\n",
       " 12  2024.01.19  74700.0  3000.0  73500.0  74700.0  73000.0  23363427.0\n",
       " 13  2024.01.18  71700.0   700.0  71600.0  72000.0  70700.0  17853397.0\n",
       " 14         NaN      NaN     NaN      NaN      NaN      NaN         NaN,\n",
       "    0   1   2   3   4   5   6   7   8   9   10  11\n",
       " 0   1   2   3   4   5   6   7   8   9  10  다음  맨뒤]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3625addf-165c-42e9-9899-69704ffbd7d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             날짜       종가     전일비       시가       고가       저가         거래량\n",
      "0    2024.01.31  72700.0  1600.0  73400.0  74000.0  72500.0  14874547.0\n",
      "1    2024.01.30  74300.0   100.0  75000.0  75300.0  73700.0  12244418.0\n",
      "2    2024.01.29  74400.0  1000.0  73800.0  75200.0  73500.0  13976521.0\n",
      "3    2024.01.26  73400.0   700.0  73700.0  74500.0  73300.0  11160062.0\n",
      "4    2024.01.25  74100.0   100.0  74200.0  74800.0  73700.0  11737747.0\n",
      "..          ...      ...     ...      ...      ...      ...         ...\n",
      "115  2023.08.10  68000.0   900.0  68300.0  68500.0  67800.0  10227311.0\n",
      "116  2023.08.09  68900.0  1300.0  68000.0  69600.0  67900.0  17259673.0\n",
      "117  2023.08.08  67600.0   900.0  69000.0  69100.0  67400.0  14664709.0\n",
      "118  2023.08.07  68500.0   200.0  67700.0  69200.0  67600.0  10968505.0\n",
      "119  2023.08.04  68300.0   500.0  68800.0  69100.0  68200.0  12360193.0\n",
      "\n",
      "[120 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import warnings\n",
    "import time\n",
    "import random\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "def crawling(url, headers, soup):\n",
    "    #각 페이지에 맞춰서 모든 페이지를 가지고 오도록하는 설정\n",
    "    last_page = int(soup.select_one('td.pgRR').a['href'].split('=')[-1])\n",
    "    \n",
    "    df = None\n",
    "    count = 0\n",
    "    for page in range(1, last_page + 1):\n",
    "      req = requests.get(f'{url}&page={page}', headers=headers)\n",
    "      df = pd.concat([df, pd.read_html(req.text, encoding = \"euc-kr\")[0]], ignore_index=True)\n",
    "      if count > 10:\n",
    "        break\n",
    "      count += 1\n",
    "      time.sleep( random.uniform(2,4)) \n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    company_code = '005930' # 삼성전자\n",
    "    url =\"https://finance.naver.com/item/sise_day.nhn?code=\" + company_code\n",
    "    \n",
    "    headers = { \n",
    "             'referer' : 'https://finance.naver.com/item/sise.naver?code=005930',\n",
    "             'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'\n",
    "            }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    result = crawling(url, headers, soup)\n",
    "    print(result)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf568d5d-60e1-462b-92cf-76e927a1114f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
